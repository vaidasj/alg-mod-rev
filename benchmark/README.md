# Algebraic Modeling Language Benchmarks

Four different algebraic modeling languages AMPL, GAMS, JuMP, and Pyomo were benchmarked. The base of the benchmark was problems available in GAMS Model library converted to scalar models in each of the analyzed modeling languages.

Two types of benchmarks based on GAMS Model libray were conducted:

1. Model instance creation time benchmark - to measure how long it take to load a model instance in a specific algebraic modeling language.
2. AMPL presolver benchmark - to analyze the efficient of AMPL presolver.

Additional benchmark against `lqcp` and `facility` models provided in ["JuMP: A Modeling Language for Mathematical Optimization"](https://github.com/mlubin/JuMPSupplement/) by I. Dunning, J. Huchette, and M. Lubin was conducted to verify JuMP benchmark results.

## Benchmark Environment

### Hardware

- Model: MacBook Pro
- Processor: Dual-Core Intel Core i5 2,9 GHz
- Memory: 16 GB

### Software

- AMPL Version 20190207
- GAMS 32.2
- JuMP 0.21.5 (Julia 1.5.1)
- Pyomo 5.7 (Python 3.8.3)
- Gurobi 9.0

## Model Instance Creation Time Benchmark

### Benchmark Methodology

1. Load model instance of a problem written in the native algebraic modeling language (_AMPL, GAMS, Pyomo_) of the modeling system.
2. Export loaded model instance to the solver compatible [NL](https://en.wikipedia.org/wiki/Nl_(format)) input format
3. Measure total (loading and exporting) execution time.

### Issues Found

- **11** AMPL models generated by GAMS Convert command were invalid, thus loading of them as AMPL model instances failed.
- **29** Pyomo models generated by GAMS Convert command were invalid, thus loading of them as Pyomo model instances failed.
- **11** JuMP models generated by GAMS Convert command were invalid, thus loading of them as JuMP model instances failed.

### Results

Detailed benchmark results for each of the models can be found [here](model-loading-times.md).

**Average loading times by model problem type in milliseconds**: 

| Type      | Models  | AMPL   | GAMS    | Pyomo   | JuMP     |
| --------- | ------- | ------ | ------- | ------- | -------  |
| CNS       | 4       | 15     | 234     | 838     | 450      |
| DNLP      | 5       | 10     | 227     | 719     | 42       |
| LP        | 56      | 19     | 241     | 844     | 898      |
| MCP       | 13      | 14     | 234     | 764     | 257      |
| MINLP     | 17      | 11     | 242     | 745     | 160      |
| MIP       | 57      | 22     | 259     | 936     | 1499     |
| MIQCP     | 4       | 11     | 238     | 852     | 72       |
| MPEC      | 1       | 10     | 236     | 669     | 19       |
| NLP       | 101     | 20     | 262     | 826     | 604      |
| QCP       | 10      | 51     | 364     | 1344    | 1380     |
| **Total** | **268** | **20** | **257** | **862** | **817**  |

> Note: averages were calculated only for models which were successfully loaded by all modeling systems.

## `lqcp` and `facility` models benchmark

Since our benchmark revealed high variation of JuMP performance and it does not fully correlate to findings in  ["JuMP: A Modeling Language for Mathematical Optimization"](https://github.com/mlubin/JuMPSupplement/) by I. Dunning, J. Huchette, and M. Lubin. Additional benchmark of `lqcp` and `facility` models provided by I. Dunning et al. was performed. 

It is important to note that JuMP underwent significant update between version 0.12 used in the original benchmark and version 0.21.5 used by us:

- An abstraction layer for working with solvers [MathOptInterface.jl](https://github.com/jump-dev/MathOptInterface.jl) was introduced
- Syntax changed for key primitives as `@variable`, `@constraint`, `optimize!` and others

Updated JuMP models can be found in [models](../models/) directory of this repository.

### Benchmark Methodology

Two different benchmarks were made:

1. Benchmark using original method by I Dunning et al. where Gurobi solver is used

   > For JuMP we've tried both [MathOptInterface.jl](https://github.com/jump-dev/MathOptInterface.jl) automatic mode and direct_model where direct model performed way better

2. Benchmark using our method independent from concrete solver and exporting NL file 

### Results

**Instance creation times using original solve with Gurobi method (milliseconds)**: 

| Model     | AMPL  | GAMS  | Pyomo  | JuMP (direct) | JuMP (MOI) |
|-----------|-------|-------|--------|---------------|------------|
| lqcp-500  | 2093  | 2271  | 17000  | 17388         | 37317      |
| lqcp-1000 | 8075  | 11995 | 139201 | 24590         | 44575      |
| lqcp-1500 | 18222 | 38813 | 322604 | 39370         | 66566      |
| lqcp-2000 | 32615 | 93586 | 575406 | 57597         | 88833      |
| fac-25    | 407   | 480   | 7442   | 17517         | 39245      |
| fac-50    | 2732  | 2884  | 43106  | 21331         | 47735      |
| fac-75    | 9052  | 12422 | 150550 | 31582         | 57432      |
| fac-100   | 20998 | 29144 | 393200 | 61326         | 93129      |

**Instance creation times using export to NL method (milliseconds)**: 

| Model     | AMPL  | GAMS   | Pyomo   | JuMP (MOI) |
|-----------|-------|--------|---------|------------|
| lqcp-500  | 2716  | 3265   | 39988   | 20424      |
| lqcp-1000 | 10503 | 14394  | 161404  | 80578      |
| lqcp-1500 | 25402 | 49822  | 307121  | 483268     |
| lqcp-2000 | 42780 | 125564 | >10 min | >10 min    |
| fac-25    | 409   | 502    | 9420    | 8163       |
| fac-50    | 2837  | 2993   | 43087   | 31799      |
| fac-75    | 10879 | 13457  | 143286  | 219548     |
| fac-100   | 23474 | 32128  | 328170  | > 10 min   |

## Presolve Benchmark

AMPL is the only of the benchmarked modeling language capable of performing model presolving before calling the solver. GAMS and Pyomo are only capable of using presolving functionality provided by the solvers themselves.

### Presolve Usage

Full AMPL presolve usage statistics can be found [here](ampl-presolve-stats.md).

AMPL presolver simplified model instances in **52.8%** of the cases, out of which:

* determined 5 models to be not feasible
* on avarage eliminated **18.42%** of constraints and **10.73%** of variables

**AMPL Presolver characteristics by model problem type**: 

| Type      | Models  | Presolved | Presolved (%) | Not Feasible | Constrains reduced | Variables reduced |
| --------- | ------- | --------- | ------------- | ------------ | ------------------ | ----------------- |
| CNS       | 4       | 4         | 100.00%       | 0            | 14.63%             | 31.39%            |
| DNLP      | 5       | 1         | 20.00%        | 0            | 0.00%              | 7.41%             |
| LP        | 57      | 21        | 36.84%        | 0            | 17.81%             | 9.66%             |
| MCP       | 19      | 17        | 89.47%        | 0            | 47.00%             | 8.56%             |
| MINLP     | 21      | 13        | 61.90%        | 1            | 16.32%             | 9.30%             |
| MIP       | 61      | 37        | 60.66%        | 0            | 19.06%             | 11.50%            |
| MIQCP     | 5       | 3         | 60.00%        | 2            | 0.00%              | 2.38%             |
| MPEC      | 1       | 1         | 100.00%       | 0            | 50.00%             | 0.00%             |
| NLP       | 101     | 48        | 47.52%        | 2            | 9.71%              | 11.55%            |
| QCP       | 10      | 6         | 60.00%        | 0            | 7.10%              | 2.55%             |
| RMIQCP    | 2       | 0         | 0.00%         | 0            | 0.00%              | 0.00%             |
| **Total** | **286** | **151**   | **52.80%**    | **5**        | **18.42%**         | **10.73%**        |

### Presolve impact on solving

In order to evaluate if AMPL presolving has a positive impact on problem solving an additional benchmark was conducted. 

The benchmark included 146 out of 151 models to which AMPL has applied presolve in the model loading benchmark. 5 models which AMPL presolve determined to be not feasible were excluded from the benchmark. 

Two attempts to solve each model were made. One with AMPL presolver turned on (default setting) and second one with AMPL presolver turned off. After each run solvers statistics including iterations count, solve time (pure solve time) and objective were gathered (MCP, CNS problems do not have objective function). 

Models were solved using Gurobi and BARON solvers:

* Gurobi Optimizer was chosen for solving LP, MIP, QCP and MIQCP type of problems
* BARON global optimality solver was chosen for solving NLP, MINLP, MCP, MPEC, CNS and DNLP problems

> CPU running time of BARON solver was constrained to 500 seconds

Solver iterations were counted in the following manner:

* for LP problems simplex iterations were counted
* for MIP problems exploration and intbasis simplex iterations were counted
* for QP barrier iterations were counted
* for all problems solved using BARON solver node iterations were counted (BARON does not expose local solver's iterations count)

It is important to note that both BARON and Gurobi solvers have their own presolve mechanisms so the provided model is simplified by the solver too. This might actually result in very similar models being solved by the solver in spite of the AMPL presolve being turned on or off. However, the focus was estimating AMPL presolve impact in real life situations, so full benchmark was executed without changing default solver behaviour. Later on an additional benchmark was made to estimate what is the impact of AMPL presolve once solver presolve functionality is turned off. 

#### Benchmark results

1. **6 models** failed to be solved due to solver limitations:
   1. `himmel11`, `tricp` (QCP) problems failed to be solved due to Gurobi not being capable to handle quadratic equality constraints
   2. `lnts`, `polygon` (NLP) problems used *cos* and *sin* operations not supported by BARON solver
   3. `maxmin` (DNLP) failed to be solved since BARON cannot handle discontinuities
   4. `traffic` (MCP) problem was too compelex for BARON to handle in given CPU time
2. **2 models** (dispatch, meanvarm) deemed to be infeasible
3. **2 models** (hhmax, lrs) were solved during AMPL presolve phase 
4. For **2 models** (hhfair, nash) optimal solution was indicated with a likelyhood of error due to numeric difficulties
5. **41 models** were solved during solver's presolve phase
6. For **6 models** mismatching objective was found with presolve turned on and off (mostly caused by the CPU time limitation imposed to the BARON solver)
7. AMPL presolve had a positive impact in **26.43%** of cases iteration wise and **47.86%** time wise. However it had a negative impact in **20.71%** iteration wise and **23.57%** time wise.

**Summary of presolve impact**

|            | Iterations wise | Time wise | Iterations wise % | Time wise % |
|------------|------|--------------|--------|--------|
| Positive   | 37   | 67           | 26.43% | 47.86% |
| Neutral   | 74   | 40           | 52.86% | 28.57% |
| Negative   | 29   | 33           | 20.71% | 23.57% |

> Table above summarizes the positive and negative impact AMPL presolve had on solving problems iteration and time wise

Detailed AMPL presolve impact on solving can be found in [ampl-solving-times.md](ampl-solving-times.md) report and [ampl-solving-times.xlsx](ampl-solving-times.xlsx) sheet *Benchmark 1*.

#### Presolve impact on solving with solver presolve turned off

As mentioned earlier both BARON and Gurobi solvers have their own presolve mechanisms. In order to test what would be an impact of AMPL pesolve if solver does not attempt to presolve a problem on its own an additional benchmark was made. Since only Gurobi allows to disable presolve functionality a subset of model was chosen for the benchmark. Detailed benchmark results can be seen in [ampl-solving-times.xlsx](ampl-solving-times.xlsx) sheet *Benchmark 2*.

**AMPL presolve impact with Gurobi presolve ON**

|          | Iterations wise | Time wise | Iterations wise % | Time wise % |
| -------- | --------------- | --------- | ----------------- | ----------- |
| Positive | 18              | 39        | 28.57%            | 61.90%      |
| Neutral  | 34              | 0         | 53.97%            | 0.00%       |
| Negative | 11              | 24        | 17.46%            | 38.10%      |

**AMPL presolve impact with Gurobi presolve OFF**

|          | Iterations wise | Time wise | Iterations wise % | Time wise % |
| -------- | --------------- | --------- | ----------------- | ----------- |
| Positive | 33              | 44        | 54.10%            | 72.13%      |
| Neutral  | 10              | 0         | 16.39%            | 0.00%       |
| Negative | 18              | 17        | 29.51%            | 27.87%      |

**Results**

1. AMPL presolve had a greater positive effect both iteration wise (+22.4%) and time wise (+10.2%) once Gurobi presolve was turned off. 
2. AMPL presolve also had less neutral impact once solver presolving was off, thus leading to a conclusion that during first benchmark some models were simplified to a very similar ones before actual solving them.
3. Gurobi was not capable to solve two MIP problems (`clad` and `mws`) in reasonable time once Gurobi presolve functionality was turned off. Those models were excluded from the benchmark.